{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function calling dataset\n",
    "\n",
    "A new dataset based on a sample of Exam_v3 will be created for the purpose of training an LLM agent capable of sending function calls when given a dialogue.\n",
    "\n",
    "The agent will track the conversation and respond with an appropriate function call given the patient and Assistant responses.\n",
    "\n",
    "It's tag will be `[Phoropter]`\n",
    "\n",
    "Function names:\n",
    "- pd_adjust(side:str, increment:int)\n",
    "  - adjusts the PD by a given increment\n",
    "- occlude(side:str)\n",
    "  - covers an eye\n",
    "- unocclude(side:str)\n",
    "  - uncovers an eye\n",
    "- display_vachart(type:str, rows:list)\n",
    "  - displays a 3-row visual acuity chart\n",
    "- resize_chart(direction:['enlarge','minimize'])\n",
    "  - changes rows on visual acuity chart\n",
    "- accuracy(letters:str)\n",
    "  - identifies the most likely chart row and checks the patient's response for accuracy\n",
    "- loadRx()\n",
    "  - loads previous prescription\n",
    "- recordAcuity(side:str, acuity)\n",
    "  - stores eye's visual acuity\n",
    "- loadAR()\n",
    "  - loads autorefractor prescription\n",
    "- add_sphere(power:int)\n",
    "  - changes spherical lens power\n",
    "- add_cylinder(power:int)\n",
    "  - changes cylindrical lens power\n",
    "- display_dots()\n",
    "  - displays astigmatic dots\n",
    "- patient_choice(choice:str (['1','2','same']))\n",
    "  - patient's selection \n",
    "- display_duochrome()\n",
    "  - displays sloan chart with red side, green side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 files found. Sampling 3 times per file.\n",
      "sampling file: /data/datasets/Exam_v3/train/000000.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000001.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000002.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000003.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000004.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000005.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000006.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000007.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000008.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000009.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000010.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000011.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000012.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000013.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000014.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000015.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000016.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000017.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000018.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000019.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000020.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000021.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000022.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000023.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000024.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000025.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000026.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000027.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000028.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000029.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000031.txt\n",
      "sampling file: /data/datasets/Exam_v3/train/000032.txt\n",
      "Expected length of data: 96\n",
      "Actual length: 96\n",
      "5 files found. Sampling 3 times per file.\n",
      "sampling file: /data/datasets/Exam_v3/val/000034.txt\n",
      "sampling file: /data/datasets/Exam_v3/val/000035.txt\n",
      "sampling file: /data/datasets/Exam_v3/val/000037.txt\n",
      "sampling file: /data/datasets/Exam_v3/val/000038.txt\n",
      "sampling file: /data/datasets/Exam_v3/val/000040.txt\n",
      "Expected length of data: 15\n",
      "Actual length: 15\n",
      "8 files found. Sampling 3 times per file.\n",
      "sampling file: /data/datasets/Exam_v3/test/000030.txt\n",
      "sampling file: /data/datasets/Exam_v3/test/000033.txt\n",
      "sampling file: /data/datasets/Exam_v3/test/000036.txt\n",
      "sampling file: /data/datasets/Exam_v3/test/000039.txt\n",
      "sampling file: /data/datasets/Exam_v3/test/000041.txt\n",
      "sampling file: /data/datasets/Exam_v3/test/000042.txt\n",
      "sampling file: /data/datasets/Exam_v3/test/000043.txt\n",
      "sampling file: /data/datasets/Exam_v3/test/000044.txt\n",
      "Expected length of data: 24\n",
      "Actual length: 24\n",
      "\n",
      " train 96\n",
      "\n",
      " val 15\n",
      "\n",
      " test 24\n"
     ]
    }
   ],
   "source": [
    "from vision_dataset import VisionDatasetCreator, VisionDataset\n",
    "\n",
    "# avg percentages of exam phase lengths\n",
    "gs_len=0.14\n",
    "sp_len=0.25\n",
    "ac_len=0.50\n",
    "cv_len=0.11\n",
    "# percentage of samples taken from each exam phase\n",
    "gs_ratio=0.15\n",
    "sp_ratio=0.30\n",
    "ac_ratio=0.40\n",
    "cv_ratio=0.15\n",
    "# minumum dialogue lengths\n",
    "gs_min = 2\n",
    "sp_min = 4\n",
    "ac_min = 8\n",
    "cv_min = 6\n",
    "# maximum dialogue lengths\n",
    "gs_max = 5\n",
    "sp_max = 14\n",
    "ac_max = 18\n",
    "cv_max = 10\n",
    "\n",
    "sampling_strategy = dict(\n",
    "    gs=[gs_len, gs_ratio, gs_min, gs_max],\n",
    "    sp=[sp_len, sp_ratio, sp_min, sp_max],\n",
    "    ac=[ac_len, ac_ratio, ac_min, ac_max],\n",
    "    cv=[cv_len, cv_ratio, cv_min, cv_max]\n",
    ")\n",
    "\n",
    "data_dir = '/data/datasets/Exam_v3/'\n",
    "# set seed to get randomization with reprducible results\n",
    "dataset_creator = VisionDatasetCreator(sampling_strategy, seed=42)\n",
    "\n",
    "# identify the number of samples from each file in the training set, which has 21 files total\n",
    "samples = 3\n",
    "# 25 samples from each file in the training set, which has 21 files total\n",
    "size = (32*samples)\n",
    "dataset_creator.load(data_dir, 'train', size)\n",
    "# 25 samples from each validation file, 3 files total\n",
    "size = (5*samples)\n",
    "dataset_creator.load(data_dir, 'val', size)\n",
    "# 25 samples from each test file, 6 files total\n",
    "size = (8*samples)\n",
    "dataset_creator.load(data_dir, 'test', size)\n",
    "\n",
    "for i in ['train', 'val', 'test']:\n",
    "    print('\\n', i, len(dataset_creator.dataset[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = VisionDataset(dataset_creator.dataset[\"train\"])\n",
    "val = VisionDataset(dataset_creator.dataset[\"val\"])\n",
    "test = VisionDataset(dataset_creator.dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue': [{'role': 'LocalTech',\n",
       "   'content': \"Alright, and I'm gonna actually, let him look at me, my nose specifically.\"},\n",
       "  {'role': 'LocalTech', 'content': 'And can her right PD come in, please?'}],\n",
       " 'response': [{'role': 'Assistant',\n",
       "   'content': 'Adjusting the right PD. Is that better?'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New dataset class - PhoropterDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis2phor(data):\n",
    "    reformatted = dict(dialogue=list(),\n",
    "                       response=list())\n",
    "    for d in data[\"dialogue\"]:\n",
    "        reformatted['dialogue'].append(d)\n",
    "    reformatted['response'].append({'role':'Phoropter', 'content':''})\n",
    "    return reformatted\n",
    "\n",
    "reformatted = vis2phor(train.data[0])\n",
    "\n",
    "def dic2txt(datadict):\n",
    "    txt = []\n",
    "    for key in datadict.keys():\n",
    "        for d in datadict[key]:\n",
    "            txt += f'''[{d['role']}]  {d['content']}\\n'''\n",
    "    return ''.join(txt)\n",
    "\n",
    "datum = dic2txt(reformatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "data_dir = '/data/datasets/phoropter_v1/'\n",
    "dset = 'train/'\n",
    "fname = f'{cnt}.txt'.zfill(10)\n",
    "fpath = f'{data_dir}{dset}{fname}'\n",
    "\n",
    "def write_file(txt, fpath):\n",
    "    with open(fpath, 'w') as file:\n",
    "        file.write(txt)\n",
    "\n",
    "write_file(datum, fpath = f'{data_dir}{dset}{fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[LocalTech]  Alright, and I'm gonna actually, let him look at me, my nose specifically.\\n[LocalTech]  And can her right PD come in, please?\\n[Phoropter]  \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset(data,data_root, split):\n",
    "    for idx in range(len(data)):\n",
    "        reformatted = vis2phor(data[idx])\n",
    "        datum = dic2txt(reformatted)\n",
    "        fname = f'{idx}.txt'.zfill(10)\n",
    "        fpath = f'{data_root}{split}{fname}'\n",
    "        write_file(datum, fpath)\n",
    "\n",
    "write_dataset(train.data, data_dir, 'train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify existing exam_v3\n",
    "\n",
    "I'm going to add a phoropter reaction to each line of text in Exam_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision_dataset import VisionDatasetCreator, VisionDataset\n",
    "from glob import glob\n",
    "# avg percentages of exam phase lengths\n",
    "gs_len=0.14\n",
    "sp_len=0.25\n",
    "ac_len=0.50\n",
    "cv_len=0.11\n",
    "# percentage of samples taken from each exam phase\n",
    "gs_ratio=0.15\n",
    "sp_ratio=0.30\n",
    "ac_ratio=0.40\n",
    "cv_ratio=0.15\n",
    "# minumum dialogue lengths\n",
    "gs_min = 2\n",
    "sp_min = 2\n",
    "ac_min = 2\n",
    "cv_min = 2\n",
    "# maximum dialogue lengths\n",
    "gs_max = 5\n",
    "sp_max = 5\n",
    "ac_max = 5\n",
    "cv_max = 5\n",
    "\n",
    "sampling_strategy = dict(\n",
    "    gs=[gs_len, gs_ratio, gs_min, gs_max],\n",
    "    sp=[sp_len, sp_ratio, sp_min, sp_max],\n",
    "    ac=[ac_len, ac_ratio, ac_min, ac_max],\n",
    "    cv=[cv_len, cv_ratio, cv_min, cv_max]\n",
    ")\n",
    "\n",
    "data_dir = '/data/datasets/Exam_v3/'\n",
    "# set seed to get randomization with reprducible results\n",
    "dataset_creator = VisionDatasetCreator(sampling_strategy, seed=42)\n",
    "\n",
    "trainPaths = glob('/data/datasets/Exam_v3/train/*.txt')\n",
    "\n",
    "captions = dataset_creator.read_captions(trainPaths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic captions where possible\n",
    "I'll try to leverage the standardization i've done to Exam_v3 to speed up the creation of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Patient__]  Number two.',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " \"[Assistant]  We're going to do the same thing now with dots. Are the dots better with one? With two? Or are they the same?\",\n",
       " \"[Phoropter]  [{'function':'display_dots'},{'function':'lens_compare'}]\",\n",
       " '[Patient__]  to',\n",
       " \"[Phoropter]  [{'function':'patient_choice','choice':'2'}]\",\n",
       " '[Assistant]  Okay. Are the dots better with one? With two? Or are they similar?',\n",
       " \"[Phoropter]  [{'function':'lens_compare'}]\",\n",
       " '[Patient__]  two.',\n",
       " \"[Phoropter]  [{'function':'patient_choice','choice':'2'}]\",\n",
       " '[Assistant]  Again, are the dots better with one, two, or are they similar?',\n",
       " \"[Phoropter]  [{'function':'lens_compare'}]\",\n",
       " '[Patient__]  two.',\n",
       " \"[Phoropter]  [{'function':'patient_choice','choice':'2'}]\",\n",
       " '[Assistant]  Are they better with one? Or two?',\n",
       " \"[Phoropter]  [{'function':'lens_compare'}]\",\n",
       " \"[Patient__]  it's the same\",\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " '[Assistant]  Great. Now I will show you choices again, but with colors in the background.  Does it look more clear with red? With green? Or are they the same?',\n",
       " \"[Phoropter]  [{'function':'display_duochrome'}]\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import Template\n",
    "\n",
    "template = Template('''[Phoropter]  [$func]''')\n",
    "ac_template = Template('''[Phoropter]  [{'function':'accuracy', 'letters':'$letters'}]''')\n",
    "\n",
    "standard = \"[Phoropter]  [{'function':None}]\"\n",
    "\n",
    "patient_choice2 = '''{'function':'patient_choice','choice':'2'}'''\n",
    "patient_choice1 = '''{'function':'patient_choice','choice':'1'}'''\n",
    "\n",
    "right_pd_adjust = '''{'function':'pd_adjust','side':'right', 'increment':-1}'''\n",
    "left_pd_adjust = '''{'function':'pd_adjust','side':'left', 'increment':-1}'''\n",
    "\n",
    "occlude_left = '''{'function':'occlude','side':'left'}'''\n",
    "occlude_right = '''{'function':'occlude','side':'right'}'''\n",
    "lens_compare = '''{'function':'lens_compare'}'''\n",
    "\n",
    "resize_chart = '''{'function':'resize_chart','enlarge':true}'''\n",
    "accuracy = '''{'function':'accuracy', 'letters':'ozrsn'}'''\n",
    "display_vachart = '''{'function':'display_vachart', 'rows':['20/35', '20/25','20/20']}'''\n",
    "display_duochrome = '''{'function':'display_duochrome'}'''\n",
    "red = '''{'function':'add_sphere','side':'right','power':-25}'''\n",
    "green = '''{'function':'add_sphere','side':'right','power':25}'''\n",
    "dots = '''[Phoropter]  [{'function':'display_dots'},{'function':'lens_compare'}]'''\n",
    "block_leftandchart = '''[Phoropter]  [{'function':'occlude', 'side':'left'},{'function':'display_vachart', 'rows':['20/35', '20/25','20/20']}]'''\n",
    "start_exam = '''[Phoropter]  [{'function':'unocclude', 'side':'left'},{'function':'unocclude', 'side':'right'},{'function':'display_vachart', 'rows':['20/35', '20/25','20/20']}]'''\n",
    "sphere_start = '''[Phoropter]  [{'function':'loadRx'},{'function':'unocclude', 'side':'left'},{'function':'unocclude', 'side':'right},{'function':'display_vachart', 'rows':['20/35', '20/25','20/20']}]'''\n",
    "ac_start = '''[Phoropter]  [{'function':'occlude', 'side':'left'},{'function':'unocclude', 'side':'right},{'function':'display_vachart', 'rows':['20/35', '20/25','20/20']}]'''\n",
    "\n",
    "l = \"[LocalTech]  \"\n",
    "a = \"[Assistant]  \"\n",
    "p = \"[patient__]  \"\n",
    "\n",
    "def has4capitals(text):\n",
    "    if len(text) < 42:\n",
    "        return sum(c.isupper() for c in text) > 3\n",
    "    else:\n",
    "        return False\n",
    "def get_letters(text):\n",
    "    letters = []\n",
    "    for c in text:\n",
    "        if c.isupper():\n",
    "            letters.append(c)\n",
    "    letters = [l.lower() for l in letters]\n",
    "    all_caps = ''.join(letters)\n",
    "    # first character will be P from Patient\n",
    "    return all_caps[1:]\n",
    "\n",
    "captions = dataset_creator.read_captions(trainPaths[1])\n",
    "def phoropter_response(data):\n",
    "    new = []\n",
    "    for cap in captions:\n",
    "        new.append(cap)\n",
    "        if \"guide you though the exam\" in cap:\n",
    "            new.append(start_exam)\n",
    "            continue\n",
    "        if \"right PD\" in cap:\n",
    "            new.append(template.substitute(func=right_pd_adjust))\n",
    "            continue\n",
    "        if \"left PD\" in cap:\n",
    "            new.append(template.substitute(func=left_pd_adjust))\n",
    "            continue\n",
    "        if cap.startswith(l) and \"start\" in cap.lower():\n",
    "            new.append(start_exam)\n",
    "            continue\n",
    "        if 'block your left eye' and \"the smallest line you can\" in cap:\n",
    "            new.append(block_leftandchart)\n",
    "            continue\n",
    "        if 'cover the left eye' and \"the smallest line you can\" in cap:\n",
    "            new.append(block_leftandchart)\n",
    "            continue\n",
    "        if \"the smallest line you can\" in cap:\n",
    "            new.append(template.substitute(func=display_vachart))\n",
    "            continue\n",
    "        if \"enlarge\" in cap:\n",
    "            new.append(template.substitute(func=resize_chart))\n",
    "            continue\n",
    "        if \"letters bigger\" in cap:\n",
    "            new.append(template.substitute(func=resize_chart))\n",
    "            continue\n",
    "        if 'cover the left eye for you' in cap:\n",
    "            new.append(template.substitute(func=occlude_left))\n",
    "            continue\n",
    "        if 'block your left eye' in cap:\n",
    "            new.append(template.substitute(func=occlude_left))\n",
    "            continue\n",
    "        if 'cover the right eye' in cap:\n",
    "            new.append(template.substitute(func=occlude_right))\n",
    "            continue\n",
    "        if 'block your right eye' in cap:\n",
    "            new.append(template.substitute(func=occlude_right))\n",
    "            continue\n",
    "        if cap.startswith(a + 'Good. Close your eyes for a moment'):\n",
    "            new.append(sphere_start)\n",
    "            continue\n",
    "        if cap.startswith(a + \"Good job. Read the smallest line you can with the right eye.\"):\n",
    "            new.append(template.substitute(func=occlude_left))\n",
    "            continue\n",
    "        if cap.startswith(a + \"Good. What's the smallest row you can read with your left eye?\"):\n",
    "            new.append(template.substitute(func=occlude_right))\n",
    "            continue\n",
    "        if cap == \"[Assistant]  Thank you. Now close your eyes again for me. Are they closed?\":\n",
    "            new.append(ac_start)\n",
    "            continue\n",
    "        if cap.lower().startswith(p + \"one\"):\n",
    "            new.append(template.substitute(func=patient_choice1))\n",
    "            continue\n",
    "        if cap.lower().startswith(p + \"two\") or cap.lower().startswith(p + \"to\") or cap.lower().startswith(p + \"too\"):\n",
    "            new.append(template.substitute(func=patient_choice2))\n",
    "            continue\n",
    "        if cap.lower().startswith(p + \"red\"):\n",
    "            new.append(template.substitute(func=red))\n",
    "            continue\n",
    "        if cap.lower().startswith(p + \"green\"):\n",
    "            new.append(template.substitute(func=green))\n",
    "            continue\n",
    "        if \"We're going to do the same thing now with dots.\" in cap:\n",
    "            new.append(dots)\n",
    "            continue\n",
    "        if \"Great! Let's compare the dots again.\" in cap:\n",
    "            new.append(dots)\n",
    "            continue\n",
    "        if \"colors in the background.\" in cap:\n",
    "            new.append(template.substitute(func=display_duochrome))\n",
    "            continue\n",
    "        if \"are they\" in cap.lower():\n",
    "            new.append(template.substitute(func=lens_compare))\n",
    "            continue\n",
    "        if \"dots\" in cap:\n",
    "            new.append(template.substitute(func=lens_compare))\n",
    "            continue\n",
    "        if \"Which color looks the most clear?\" in cap:\n",
    "            new.append(template.substitute(func=display_duochrome))\n",
    "            continue\n",
    "        if has4capitals(cap):\n",
    "            accuracy = ac_template.substitute(letters=get_letters(cap))\n",
    "            new.append(accuracy)\n",
    "            continue\n",
    "        else:\n",
    "            new.append(standard)\n",
    "    return new\n",
    "new = phoropter_response(captions)\n",
    "new[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(txt, fpath):\n",
    "    with open(fpath, 'w') as file:\n",
    "        file.writelines(l + '\\n' for l in txt)\n",
    "def write_dataset(data,data_root, split):\n",
    "    for idx in range(len(data)):\n",
    "        reformatted = vis2phor(data[idx])\n",
    "        datum = dic2txt(reformatted)\n",
    "        fname = f'{idx}.txt'.zfill(10)\n",
    "        fpath = f'{data_root}{split}{fname}'\n",
    "        write_file(datum, fpath)\n",
    "\n",
    "data_dir = '/data/datasets/Exam_v3/'\n",
    "# set seed to get randomization with reprducible results\n",
    "dataset_creator = VisionDatasetCreator(sampling_strategy, seed=42)\n",
    "\n",
    "output_dir = '/data/datasets/phoropter_v2/'\n",
    "for split in ['train', 'val','test']:\n",
    "    filePaths = sorted(glob('/data/datasets/Exam_v3/' + split + '/*.txt'))\n",
    "    for idx, f in enumerate(filePaths):\n",
    "\n",
    "        captions = dataset_creator.read_captions(f)\n",
    "        phoropter = phoropter_response(captions)\n",
    "        fname = f'{idx}.txt'.zfill(10)\n",
    "        fpath = f'{output_dir}{split}/{fname}'\n",
    "        write_file(phoropter, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/datasets/Exam_v3/train/000032.txt'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "filePaths = sorted(glob('/data/datasets/Exam_v3/train/*.txt'))\n",
    "filePaths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Patient__]  K B N R. length:  21\n",
      "[Patient__]  HBZD? length:  18\n",
      "[Patient__]  RKBH. length:  18\n",
      "[Patient__]  OZRSN. length:  19\n",
      "[Patient__]  O R K S E. length:  23\n",
      "[Patient__]  NCKHD. length:  19\n",
      "[Patient__]  CZSHN length:  18\n",
      "[Patient__]  O R K S E. length:  23\n",
      "[Patient__]  Yeah, A P E O R F D Z. length:  35\n"
     ]
    }
   ],
   "source": [
    "def has4capitals(text):\n",
    "    if len(text) < 42:\n",
    "        return sum(c.isupper() for c in text) > 3\n",
    "    else:\n",
    "        return False\n",
    "for i in captions:\n",
    "    if has4capitals(i):\n",
    "        print(i, \"length: \",len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg percentages of exam phase lengths\n",
    "gs_len=0.14\n",
    "sp_len=0.25\n",
    "ac_len=0.50\n",
    "cv_len=0.11\n",
    "# percentage of samples taken from each exam phase\n",
    "gs_ratio=0.15\n",
    "sp_ratio=0.30\n",
    "ac_ratio=0.40\n",
    "cv_ratio=0.15\n",
    "# minumum dialogue lengths\n",
    "gs_min = 2\n",
    "sp_min = 2\n",
    "ac_min = 2\n",
    "cv_min = 2\n",
    "# maximum dialogue lengths\n",
    "gs_max = 5\n",
    "sp_max = 5\n",
    "ac_max = 5\n",
    "cv_max = 5\n",
    "\n",
    "sampling_strategy = dict(\n",
    "    gs=[gs_len, gs_ratio, gs_min, gs_max],\n",
    "    sp=[sp_len, sp_ratio, sp_min, sp_max],\n",
    "    ac=[ac_len, ac_ratio, ac_min, ac_max],\n",
    "    cv=[cv_len, cv_ratio, cv_min, cv_max]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 files found. Sampling 3 times per file.\n",
      "sampling file: /data/datasets/phoropter_v2/train/000000.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000001.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000002.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000003.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000004.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000005.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000006.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000007.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000008.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000009.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000010.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000011.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000012.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000013.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000014.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000015.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000016.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000017.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000018.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000019.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000020.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000021.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000022.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000023.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000024.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000025.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000026.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000027.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000028.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000029.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000030.txt\n",
      "sampling file: /data/datasets/phoropter_v2/train/000031.txt\n",
      "Expected length of data: 96\n",
      "Actual length: 96\n",
      "5 files found. Sampling 3 times per file.\n",
      "sampling file: /data/datasets/phoropter_v2/val/000000.txt\n",
      "sampling file: /data/datasets/phoropter_v2/val/000001.txt\n",
      "sampling file: /data/datasets/phoropter_v2/val/000002.txt\n",
      "sampling file: /data/datasets/phoropter_v2/val/000003.txt\n",
      "sampling file: /data/datasets/phoropter_v2/val/000004.txt\n",
      "Expected length of data: 15\n",
      "Actual length: 15\n",
      "8 files found. Sampling 3 times per file.\n",
      "sampling file: /data/datasets/phoropter_v2/test/000000.txt\n",
      "sampling file: /data/datasets/phoropter_v2/test/000001.txt\n",
      "sampling file: /data/datasets/phoropter_v2/test/000002.txt\n",
      "sampling file: /data/datasets/phoropter_v2/test/000003.txt\n",
      "sampling file: /data/datasets/phoropter_v2/test/000004.txt\n",
      "sampling file: /data/datasets/phoropter_v2/test/000005.txt\n",
      "sampling file: /data/datasets/phoropter_v2/test/000006.txt\n",
      "sampling file: /data/datasets/phoropter_v2/test/000007.txt\n",
      "Expected length of data: 24\n",
      "Actual length: 24\n",
      "\n",
      " train 96\n",
      "\n",
      " val 15\n",
      "\n",
      " test 24\n"
     ]
    }
   ],
   "source": [
    "from vision_dataset import VisionDatasetCreator\n",
    "\n",
    "\n",
    "data_dir = '/data/datasets/phoropter_v2/'\n",
    "# set seed to get randomization with reprducible results\n",
    "dataset_creator = VisionDatasetCreator(sampling_strategy=sampling_strategy, seed=42, assistant=False)\n",
    "\n",
    "# identify the number of samples from each file in the training set, which has 21 files total\n",
    "samples = 3\n",
    "# 25 samples from each file in the training set, which has 21 files total\n",
    "size = (32*samples)\n",
    "dataset_creator.load(data_dir, 'train', size)\n",
    "# 25 samples from each validation file, 3 files total\n",
    "size = (5*samples)\n",
    "dataset_creator.load(data_dir, 'val', size)\n",
    "# 25 samples from each test file, 6 files total\n",
    "size = (8*samples)\n",
    "dataset_creator.load(data_dir, 'test', size)\n",
    "\n",
    "for i in ['train', 'val', 'test']:\n",
    "    print('\\n', i, len(dataset_creator.dataset[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision_dataset import VisionDataset\n",
    "\n",
    "train = VisionDataset(dataset_creator.dataset[\"train\"])\n",
    "val = VisionDataset(dataset_creator.dataset[\"val\"])\n",
    "test = VisionDataset(dataset_creator.dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialogue': [{'role': 'Phoropter', 'content': \"[{'function':None}]\"},\n",
       "  {'role': 'Assistant', 'content': 'Hello! Is [PATIENT] with us today?'}],\n",
       " 'response': [{'role': 'Phoropter', 'content': \"[{'function':None}]\"}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find 'hzcko' sequences\n",
    "\n",
    "One technician doesn't like to change the letters on the screen, so they show 'hzcko' to all their patients. I want to randomize those sequences.\n",
    "\n",
    "First, I'll clean these sequences from Exam_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'U'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "import string\n",
    "caps = list(string.ascii_uppercase)\n",
    "\n",
    "idx = randint(0, len(caps))\n",
    "caps[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision_dataset import VisionDatasetCreator\n",
    "from glob import glob\n",
    "import string\n",
    "from random import randint\n",
    "\n",
    "def write_file(txt, fpath):\n",
    "    with open(fpath, 'w') as file:\n",
    "        file.writelines(l + '\\n' for l in txt)\n",
    "\n",
    "filePaths = sorted(glob('/data/datasets/Exam_v3/test/*.txt'))\n",
    "\n",
    "creator = VisionDatasetCreator(sampling_strategy=sampling_strategy)\n",
    "\n",
    "caps = list(string.ascii_uppercase)\n",
    "for f in filePaths:\n",
    "    captions = creator.read_captions(f)\n",
    "    fname = f.split('/')[-1]\n",
    "    for n in range(len(captions)):\n",
    "        if 'H Z C' in captions[n]:\n",
    "            print(f, '\\n',captions[n])\n",
    "            for l in 'HZCKO':\n",
    "                idx = randint(0, len(caps)-1)\n",
    "                captions[n]= captions[n].replace(l,caps[idx])\n",
    "            print(captions[n])\n",
    "    # write_file(captions,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same for phoropter_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths = sorted(glob('/data/datasets/phoropter_v2/train/*.txt'))\n",
    "\n",
    "creator = VisionDatasetCreator(sampling_strategy=sampling_strategy)\n",
    "\n",
    "caps_upper = list(string.ascii_uppercase)\n",
    "caps_lower = list(string.ascii_lowercase)\n",
    "for f in filePaths:\n",
    "    captions = creator.read_captions(f)\n",
    "    fname = f.split('/')[-1]\n",
    "    for n in range(len(captions)):\n",
    "        if 'H Z C' in captions[n]:\n",
    "            print(f, '\\n',captions[n],'\\n',captions[n+1][:-8])\n",
    "            letters = captions[n+1][-8:]\n",
    "            for l in 'HZCKO':\n",
    "                idx = randint(0, len(caps_upper)-1)\n",
    "                captions[n]= captions[n].replace(l,caps_upper[idx])\n",
    "                letters = letters.replace(l.lower(),caps_lower[idx])\n",
    "            captions[n+1] = captions[n+1][:-8] + letters\n",
    "            print(captions[n],'\\n',captions[n+1])\n",
    "    write_file(captions,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limiting Phoropter repsonses\n",
    "\n",
    "We are directed to limit the communications with Gordon's code to just patient selections and letter identification.\n",
    "\n",
    "To this end, no commands, hypothetical or otherwise will be sent to Gordon's code. We will only send the identified patient responses.\n",
    "\n",
    "Responses that contain any function other than `patient_choice` or `accuracy` will be changed to `None`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision_dataset import VisionDatasetCreator, VisionDataset\n",
    "from glob import glob\n",
    "# avg percentages of exam phase lengths\n",
    "gs_len=0.14\n",
    "sp_len=0.25\n",
    "ac_len=0.50\n",
    "cv_len=0.11\n",
    "# percentage of samples taken from each exam phase\n",
    "gs_ratio=0.15\n",
    "sp_ratio=0.30\n",
    "ac_ratio=0.40\n",
    "cv_ratio=0.15\n",
    "# minumum dialogue lengths\n",
    "gs_min = 2\n",
    "sp_min = 2\n",
    "ac_min = 2\n",
    "cv_min = 2\n",
    "# maximum dialogue lengths\n",
    "gs_max = 5\n",
    "sp_max = 5\n",
    "ac_max = 5\n",
    "cv_max = 5\n",
    "\n",
    "sampling_strategy = dict(\n",
    "    gs=[gs_len, gs_ratio, gs_min, gs_max],\n",
    "    sp=[sp_len, sp_ratio, sp_min, sp_max],\n",
    "    ac=[ac_len, ac_ratio, ac_min, ac_max],\n",
    "    cv=[cv_len, cv_ratio, cv_min, cv_max]\n",
    ")\n",
    "\n",
    "data_dir = '/data/datasets/phoropter_v3/'\n",
    "# set seed to get randomization with reprducible results\n",
    "dataset_creator = VisionDatasetCreator(sampling_strategy, seed=42)\n",
    "\n",
    "trainPaths = glob('/data/datasets/phoropter_v3/train/*.txt')\n",
    "\n",
    "captions = dataset_creator.read_captions(trainPaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dset in ['train', 'val', 'test']:\n",
    "    paths = sorted(glob(f'/data/datasets/phoropter_v3/{dset}/*.txt'))\n",
    "    for p in paths:\n",
    "        captions = dataset_creator.read_captions(p)\n",
    "        for idx in range(len(captions)):\n",
    "            if captions[idx].startswith(\"[Phoropter]\"):\n",
    "                if not captions[idx][13] == \"[\":\n",
    "                    print(f\"{p}\\n{captions[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[17][13:].startswith(\"[{'function':'pd_adjust'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[LocalTech]  hello.',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " '[Assistant]  Hello! Is [PATIENT] with us today?',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " '[LocalTech]  Yes',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " '[Assistant]  Great! I\\'m [ASSISTANT]. I\\'ll guide you though the exam before you see the doctor today. [LOCALTECH] will get you set up. [LOCALTECH], just say \"[ASSISTANT], start the exam\", and I\\'ll know you\\'re ready to start. If the PDs need adjusting, I can do that, too.',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " '[LocalTech]  Okay. And nose pads, if you ever wanted to know, are usually more uncomfortable when it comes to normal stuff because they sit on your nose quite tightly.  So if you ever wanted to try a plastic lens, an optician will go over that too, okay?',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " \"[Patient__]  Right, yeah.  That's why I was looking at the plastic.  It's a lot more gentle.  I wear it a lot of times.\",\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " \"[LocalTech]  Alright, and I'm gonna actually, let him look at me, my nose specifically.\",\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " '[LocalTech]  And can her right PD come in, please?',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " '[Assistant]  Adjusting the right PD. Is that better?',\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " \"[LocalTech]  Yes, I'm just sorry, I'm adjusting them.\",\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " \"[Assistant]  [LOCALTECH], let me know when you're ready to begin.\",\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " \"[Patient__]  That's perfect. Thank you.\",\n",
       " \"[Phoropter]  [{'function':None}]\",\n",
       " \"[LocalTech]  She's ready. Start the exam.\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard = \"[Phoropter]  [{'function':None}]\"\n",
    "choice_same = \"[Phoropter]  [{'function':'patient_choice','choice':'same'}]\"\n",
    "def replacement(txt):\n",
    "    if txt.startswith('[Ph'):\n",
    "        if txt[13:].startswith(\"[{'function':'accuracy'\"):\n",
    "            return txt\n",
    "        elif txt[13:].startswith(\"[{'function':'patient_choice'\"):\n",
    "            return txt\n",
    "        elif txt[13:].startswith(\"[{'function':'display_duochrome\"):\n",
    "            return choice_same\n",
    "        elif txt[13:].startswith(\"[{'function':'display_vachart\"):\n",
    "            return choice_same\n",
    "        else:\n",
    "            return standard\n",
    "    else:\n",
    "        return txt\n",
    "\n",
    "for idx in range(len(captions)):\n",
    "    captions[idx] = replacement(captions[idx])\n",
    "captions[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(txt, fpath):\n",
    "    with open(fpath, 'w') as file:\n",
    "        file.writelines(l + '\\n' for l in txt)\n",
    "\n",
    "for dset in ['train', 'val', 'test']:\n",
    "    paths = sorted(glob(f'/data/datasets/phoropter_v3/{dset}/*.txt'))\n",
    "    for p in paths:\n",
    "        captions = dataset_creator.read_captions(p)\n",
    "        for idx in range(len(captions)):\n",
    "            captions[idx] = replacement(captions[idx])\n",
    "        write_file(captions, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phoropter V4\n",
    "\n",
    "Now I'll make a dataset with the objective of training a multi-label text classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0, '2': 1, 'letters': 3, 'other': 4, 'same': 2}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_labels = [\"1\", \"2\", \"same\", \"letters\", \"other\"]\n",
    "ints = range(len(candidate_labels))\n",
    "mapping = dict(zip(candidate_labels,ints))\n",
    "mapping = {k:v for k,v in sorted(mapping.items(), key= lambda x:x[0])}\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab = 2\n",
    "def onehot(label):\n",
    "    num_labels = 5\n",
    "    new = [0 for i in range(num_labels)]\n",
    "    new[lab-1] = 1\n",
    "    return new\n",
    "\n",
    "onehot(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 files found.\n",
      "num utterances: 693 labels: 693\n",
      "5 files found.\n",
      "num utterances: 113 labels: 113\n",
      "8 files found.\n",
      "num utterances: 206 labels: 206\n",
      "train\n",
      "Right, yeah.  That's why I was looking at the plastic.  It's a lot more gentle.  I wear it a lot of times. [0, 0, 0, 1, 0]\n",
      "That's perfect. Thank you. [0, 0, 0, 1, 0]\n",
      "Okay, O N V E R. [0, 0, 1, 0, 0]\n",
      "OK.  O H Y Q K. [0, 0, 1, 0, 0]\n",
      "O N V E R. [0, 0, 1, 0, 0]\n",
      "val\n",
      "Thank you. [0, 0, 0, 1, 0]\n",
      "S is, excuse me, SZR. [0, 0, 1, 0, 0]\n",
      "Um, S Z R. [0, 0, 1, 0, 0]\n",
      "O K [0, 0, 1, 0, 0]\n",
      "yes [0, 0, 0, 1, 0]\n",
      "test\n",
      "Hello? [0, 0, 0, 1, 0]\n",
      "That's me. [0, 0, 0, 1, 0]\n",
      "And I think that we're ready. [0, 0, 0, 1, 0]\n",
      "It's blurry, but ZHC. [0, 0, 1, 0, 0]\n",
      "VHC. [0, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from text_classification_dataset import TextClassificationDatasetCreator\n",
    "\n",
    "# set seed to get randomization with reprducible results\n",
    "dataset_creator = TextClassificationDatasetCreator()\n",
    "\n",
    "dsets= []\n",
    "for dset in ['train', 'val', 'test']:\n",
    "    data_dir= f'/data/datasets/phoropter_v4/{dset}'\n",
    "    data = dataset_creator.dset(dset,data_dir=data_dir)\n",
    "    dsets.append(data)\n",
    "\n",
    "for name, dset in zip(['train', 'val', 'test'], dsets):\n",
    "    print(name)\n",
    "    for i in range(5):\n",
    "        print(dset['text'][i], dset['label'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/digitalopt/miniconda3/envs/llama-train2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "# !python -m pip install setfit\n",
    "train = Dataset.from_dict(dsets[0])\n",
    "val = Dataset.from_dict(dsets[1])\n",
    "test = Dataset.from_dict(dsets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setfit import get_templated_dataset\n",
    "\n",
    "# dummy_dataset = Dataset.from_dict({})\n",
    "# train = get_templated_dataset(dummy_dataset, candidate_labels, sample_size=8)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = train.shuffle()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['yes they are',\n",
       "  'The first one.',\n",
       "  'yeah',\n",
       "  'K D N R O.',\n",
       "  \"they're practically the same\"],\n",
       " 'label': [[0, 0, 0, 1, 0],\n",
       "  [0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 1, 0],\n",
       "  [0, 0, 1, 0, 0],\n",
       "  [0, 1, 0, 0, 0]]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shuffle()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_id = \"sentence-transformers/paraphrase-mpnet-base-v2\"\n",
    "# model_id ='sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = SetFitModel.from_pretrained(model_id,\n",
    "                                    multi_target_strategy=\"one-vs-rest\",\n",
    "                                    use_differentiable_head=True,\n",
    "                                    head_params={\"out_features\": dataset_creator.num_classes})\n",
    "# model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Early stopping patience (number of epochs without improvement)\n",
    "early_stopping_patience = 2\n",
    "\n",
    "# Early stopping threshold (minimum relative improvement to continue training)\n",
    "early_stopping_threshold = -0.001\n",
    "\n",
    "# Create the callback\n",
    "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience, early_stopping_threshold)\n",
    "\n",
    "# def compute_metrics(p):    \n",
    "#     pred, labels = p\n",
    "#     pred = np.argmax(pred, axis=1)\n",
    "#     accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "#     recall = recall_score(y_true=labels, y_pred=pred)\n",
    "#     precision = precision_score(y_true=labels, y_pred=pred)\n",
    "#     f1 = f1_score(y_true=labels, y_pred=pred)    \n",
    "#     return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "from setfit import Trainer, TrainingArguments\n",
    "args = TrainingArguments(\n",
    "    batch_size=64,\n",
    "    logging_steps=10,\n",
    "    eval_steps=50,\n",
    "    save_steps=50,\n",
    "    num_epochs=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    metric_for_best_model='eval_embedding_loss',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "trainer = Trainer(model=model,\n",
    "                  train_dataset=train,\n",
    "                  eval_dataset=val,\n",
    "                  callbacks=[early_stopping_callback], \n",
    "                  args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 316214\n",
      "  Batch size = 64\n",
      "  Num epochs = 4\n",
      "  Total optimization steps = 19764\n",
      "  0%|          | 0/19764 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2239, 'learning_rate': 1.0116337885685383e-08, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2444, 'learning_rate': 1.0116337885685383e-07, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2321, 'learning_rate': 2.0232675771370766e-07, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2406, 'learning_rate': 3.034901365705615e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2352, 'learning_rate': 4.046535154274153e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2154, 'learning_rate': 5.058168942842692e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.1965, 'learning_rate': 5.058168942842692e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1802, 'learning_rate': 6.06980273141123e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2137, 'learning_rate': 7.081436519979768e-07, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2082, 'learning_rate': 8.093070308548306e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2054, 'learning_rate': 9.104704097116844e-07, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2082, 'learning_rate': 1.0116337885685384e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.1652, 'learning_rate': 1.0116337885685384e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1585, 'learning_rate': 1.112797167425392e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.155, 'learning_rate': 1.213960546282246e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1592, 'learning_rate': 1.3151239251391e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.154, 'learning_rate': 1.4162873039959535e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1637, 'learning_rate': 1.5174506828528073e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.1282, 'learning_rate': 1.5174506828528073e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1247, 'learning_rate': 1.6186140617096613e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.132, 'learning_rate': 1.7197774405665153e-06, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1146, 'learning_rate': 1.8209408194233688e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1051, 'learning_rate': 1.9221041982802226e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.115, 'learning_rate': 2.023267577137077e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0889, 'learning_rate': 2.023267577137077e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1061, 'learning_rate': 2.12443095599393e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1087, 'learning_rate': 2.225594334850784e-06, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.098, 'learning_rate': 2.326757713707638e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0983, 'learning_rate': 2.427921092564492e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0951, 'learning_rate': 2.5290844714213457e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0676, 'learning_rate': 2.5290844714213457e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0505, 'learning_rate': 2.6302478502782e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0699, 'learning_rate': 2.7314112291350532e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|         | 271/19764 [01:45<1:22:28,  3.94it/s]\u001b[A\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0385, 'learning_rate': 2.832574607991907e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0543, 'learning_rate': 2.933737986848761e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0766, 'learning_rate': 3.0349013657056146e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0544, 'learning_rate': 3.0349013657056146e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0538, 'learning_rate': 3.1360647445624688e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0491, 'learning_rate': 3.2372281234193226e-06, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0333, 'learning_rate': 3.3383915022761763e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0401, 'learning_rate': 3.4395548811330305e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0603, 'learning_rate': 3.540718259989884e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0463, 'learning_rate': 3.540718259989884e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0433, 'learning_rate': 3.6418816388467377e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0442, 'learning_rate': 3.7430450177035914e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0347, 'learning_rate': 3.844208396560445e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0384, 'learning_rate': 3.945371775417299e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0282, 'learning_rate': 4.046535154274154e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0422, 'learning_rate': 4.046535154274154e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0255, 'learning_rate': 4.147698533131007e-06, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0705, 'learning_rate': 4.24886191198786e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0239, 'learning_rate': 4.3500252908447145e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0203, 'learning_rate': 4.451188669701568e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0283, 'learning_rate': 4.552352048558422e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0412, 'learning_rate': 4.552352048558422e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0446, 'learning_rate': 4.653515427415276e-06, 'epoch': 0.09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0114, 'learning_rate': 4.75467880627213e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0106, 'learning_rate': 4.855842185128984e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0133, 'learning_rate': 4.957005563985838e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0091, 'learning_rate': 5.058168942842691e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0417, 'learning_rate': 5.058168942842691e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0368, 'learning_rate': 5.159332321699545e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.033, 'learning_rate': 5.2604957005564e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0234, 'learning_rate': 5.361659079413253e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0242, 'learning_rate': 5.4628224582701065e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0223, 'learning_rate': 5.563985837126961e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      "\u001b[A                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_embedding_loss': 0.0425, 'learning_rate': 5.563985837126961e-06, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best SentenceTransformer model from step 450.\n",
      "\n",
      "  3%|         | 550/19764 [03:46<2:11:40,  2.43it/s]\n",
      "The `max_length` is `None`. Using the maximum acceptable length according to the current model body: 512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 226.1461, 'train_samples_per_second': 5593.269, 'train_steps_per_second': 87.395, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|| 4/4 [00:36<00:00,  9.08s/it]\n",
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.912621359223301}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.eval_dataset = test\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SetFitModel.__init__() got an unexpected keyword argument 'head_params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/digitalopt/proj/diarization/checkpoints/step_550\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model_id ='sentence-transformers/all-MiniLM-L6-v2'\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSetFitModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mmulti_target_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mone-vs-rest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43muse_differentiable_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mhead_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-train2/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-train2/lib/python3.11/site-packages/huggingface_hub/hub_mixin.py:157\u001b[0m, in \u001b[0;36mModelHubMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, force_download, resume_download, proxies, token, cache_dir, local_files_only, revision, **model_kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m         config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    155\u001b[0m     model_kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config})\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-train2/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama-train2/lib/python3.11/site-packages/setfit/modeling.py:869\u001b[0m, in \u001b[0;36mSetFitModel._from_pretrained\u001b[0;34m(cls, model_id, revision, cache_dir, force_download, proxies, resume_download, local_files_only, token, multi_target_strategy, use_differentiable_head, device, trust_remote_code, **model_kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Remove the `transformers` config\u001b[39;00m\n\u001b[1;32m    868\u001b[0m model_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_head\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_head\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_target_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_target_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_card_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_card_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentence_transformers_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentence_transformers_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: SetFitModel.__init__() got an unexpected keyword argument 'head_params'"
     ]
    }
   ],
   "source": [
    "model_id = \"/home/digitalopt/proj/diarization/checkpoints/step_550\"\n",
    "# model_id ='sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = SetFitModel.from_pretrained(model_id,\n",
    "                                    multi_target_strategy=\"one-vs-rest\",\n",
    "                                    use_differentiable_head=True,\n",
    "                                    head_params={\"out_features\": dataset_creator.num_classes})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-train2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
